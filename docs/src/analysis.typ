#import "@preview/tablem:0.3.0": tablem

== 训练集数据分析
=== 训练集数据展示
你的训练集情感分布是：
#grid(columns: (1fr, 1fr))[
#figure(
  tablem[
    | 情感标签 | 含义            | 样本数        | 占比（约）     |
    | ---- | ------------- | ---------- | --------- |
    | 0    | Very Negative | 7,072      | 4.5%      |
    | 1    | Negative      | 27,273     | 17.4%     |
    | 2    | Neutral       | 79,582     | 50.8%     |
    | 3    | Positive      | 32,927     | 21.0%     |
    | 4    | Very Positive | 9,206      | 5.9%      |
  ],
  caption: "训练集情感分布统计"
)][
#figure(image("assets/data/sentiment_label_bar.png", width: 50%))
]


#block(fill: luma(240), inset: 8pt, radius: 4pt)[
  _这是一个以 Neutral 为主导、极端情感样本稀缺的严重不均衡多分类数据集。_
]


=== 数据明显「类别不平衡」
- Neutral（2）$approx$ *占一半*
- Very Negative / Very Positive < *6%*
- 多数类样本 $approx$ 少数类样本的 *10 倍以上*

#block(stroke: (left: 4pt + gray), inset: (left: 1em))[
  模型在训练时会天然偏向预测 Neutral。
]

=== Accuracy 是一个「危险指标」

如果一个模型 *什么都不学*：
永远预测 Sentiment = 2
它的 accuracy 就是：

```text
≈ 50.8%
```
这意味着：55% 以下 −>模型几乎没学，60% −>只是比瞎猜稍好

你可以直接说明：Accuracy 不是唯一指标
=== 极端情感（0 / 4）是「最难学的」
Very Negative + Very Positive =10.4%

但它们在实际应用中最重要

模型很容易把：
0 =−> 1 / 2、4 −> 3 / 2的情感“强度”被削弱
=== 这是一个「现实世界数据集」
这点其实很重要，也很加分。
你这张图说明：
大多数评论是中性或轻微情感
极端情绪本来就少
数据分布符合真实用户行为，而非人工平衡数据。

#import "@preview/tablem:0.3.0": tablem

// ==========================================
// 4.2 模型性能对比实验
// ==========================================

== 模型性能对比实验

为了探究不同模型架构在情感分类任务上的性能边界，我们对比了三种具有代表性的模型：
1.  *LSTM (Baseline)*: 双向 LSTM，代表传统的循环神经网络。
2.  *TinyLLM (Custom)*: 自定义的 16 层 Transformer 架构，代表从零训练的注意力机制模型。
3.  *RoBERTa-Large (Fine-tuned)*: 基于预训练权重的微调模型，代表当前 NLP 的主流范式。

=== 核心指标对比

下表展示了三个模型在验证集上的最佳性能指标。可以看到，随着模型复杂度的提升和预训练机制的引入，各项指标均有显著提升。

#figure(
  tablem[
    | 模型架构 | Val Accuracy | Val Loss | Macro-F1 | 极端情感召回 (Class 0/4) |
    | :--- | :--- | :--- | :--- | :--- |
    | *LSTM* | 58.50% | 1.0592 | 0.41 | 极差 (~13% / 21%) |
    | *TinyLLM* | 66.13% | 0.8117 | 0.54 | 较差 (~23% / 30%) |
    | *RoBERTa* | *70.00%* | *0.7256* | *0.62* | *尚可 (~47% / 57%)* |
  ],
  caption: "三大模型最佳性能指标对比"
)

#block(fill: luma(240), inset: 8pt, radius: 4pt)[
  *结论：* 虽然 Accuracy 的差距看似只有 12% (58% vs 70%)，但 *Macro-F1* 的差距高达 0.21，这说明 RoBERTa 在处理类别不平衡问题上具有压倒性优势。
]


=== 训练动态与过拟合分析

通过分析训练日志中的 Loss 变化，我们发现三种模型表现出了截然不同的训练特性：

1.  *LSTM (欠拟合/瓶颈)*:
    - 验证集 Loss 始终较高 (停留在 1.05 左右)。
    - 模型难以捕捉文本深层的语义特征，性能在 58% 左右触达天花板。

2.  *TinyLLM (严重过拟合)*:
    - *"昙花一现"*：模型在 Epoch 1 就达到了最佳性能 (Loss 0.81)。
    - 随后验证集 Loss 迅速飙升至 1.00 以上，甚至超过了 LSTM。这表明模型参数量对于该数据集可能过大，或者在没有预训练知识的情况下，模型倾向于死记硬背训练数据中的噪声。

3.  *RoBERTa-Large (稳健收敛)*:
    - 验证集 Loss 持续下降并稳定在 0.73 左右。
    - 得益于大规模预训练，模型具备极强的泛化能力，未出现明显的过拟合迹象。



=== 极端情感捕捉能力分析 (Recall Analysis)

本任务最大的难点在于 *类别不平衡* (Neutral 占 50%)。我们重点关注模型对 *Very Negative (0)* 和 *Very Positive (4)* 的识别能力。

#figure(
  tablem[
    | 真实标签 | LSTM Recall | TinyLLM Recall | RoBERTa Recall |
    | :--- | :--- | :--- | :--- | 
    | **0 (极负)** | 13% | 23% | 47% | 
    | **1 (负面)** | 40% | 52% | 61% | 
    | **2 (中性)** | 81% | 80% | 79% | 
    | **3 (正面)** | 40% | 57% | 62% | 
    | **4 (极正)** | 21% | 30% | 57% | 
  ],
  caption: "各类别召回率 (Recall) 详细对比"
)

*数据洞察：*
- *LSTM* 几乎是“瞎猜”极端情感，它倾向于把所有极端样本都预测为中性。
- *TinyLLM* 开始具备一定的区分能力，但仍漏掉了 70% 以上的极端样本。
- *RoBERTa* 实现了质的飞跃，它不再盲目从众，而是敢于预测极端类别。

#block(stroke: (left: 4pt + gray), inset: (left: 1em))[
  这证明了 **预训练语言模型 (PLM)** 对于理解情感的细微程度（Nuance）和“强度”（Intensity）至关重要。
]


=== 混淆矩阵形态分析

对比三个模型的混淆矩阵，可以清晰地看到预测分布的变化趋势：

1.  *中心坍缩 (LSTM)*: 预测结果高度集中在 Label 2 (Neutral) 列，呈现垂直长条状。模型采取了“由于不确定，所以猜中性”的保守策略。
2.  *对角线强化 (RoBERTa)*: 混淆矩阵的对角线明显变亮，特别是在 Label 0 和 Label 4 的角落。这代表模型真正理解了语义，而非利用数据分布漏洞。
3.  *邻类漂移 (Common Issue)*: 所有模型的主要错误都集中在 *相邻类别* (如把 0 预测成 1，把 4 预测成 3)。几乎没有模型会将 0 预测成 4。这说明模型都成功学到了情感的 *连续性特征*。

=== 小结

通过对比 LSTM、TinyLLM 和 RoBERTa-Large 的表现，我们得出以下结论：

1.  *架构决定上限*：LSTM 受限于结构，无法有效处理长文本和复杂语义；Transformer 架构（TinyLLM/RoBERTa）显著优于 RNN。
2.  *预训练是关键*：在小样本（极端类别样本少）场景下，RoBERTa 携带的先验知识是解决 *Cold Start* 和 *不平衡问题* 的关键。从零训练的 TinyLLM 容易陷入过拟合。
3.  *Accuracy 的欺骗性*：LSTM 的 58% Accuracy 背后是接近 0 的极端情感召回率；RoBERTa 的 70% Accuracy 代表了更均衡、更可用的模型。

#v(1em)
#line(length: 100%, stroke: 0.5pt + gray)