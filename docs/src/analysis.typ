#import "@preview/tablem:0.3.0": tablem

== 最终模型性能对比

=== 核心指标对比

下表展示了三个模型在验证集上的最佳性能指标。可以看到，随着模型复杂度的提升和预训练机制的引入，各项指标均有显著提升。

#figure(
  tablem[
    | 模型架构 | Val Accuracy | Val Loss | Macro-F1 | 极端情感召回 (Class 0/4) |
    | :--- | :--- | :--- | :--- | :--- |
    | *LSTM* | 58.50% | 1.0592 | 0.41 | 极差 (~13% / 21%) |
    | *TinyLLM* | 66.13% | 0.8117 | 0.54 | 较差 (~23% / 30%) |
    | *RoBERTa* | *70.00%* | *0.7256* | *0.62* | *尚可 (~47% / 57%)* |
  ],
  caption: "三大模型最佳性能指标对比"
)

#block(fill: luma(240), inset: 8pt, radius: 4pt)[
  *结论：* 虽然 Accuracy 的差距看似只有 12% (58% vs 70%)，但 *Macro-F1* 的差距高达 0.21，这说明 RoBERTa 在处理类别不平衡问题上具有压倒性优势。
]

---

=== 训练动态与过拟合分析

通过分析训练日志中的 Loss 变化，我们发现三种模型表现出了截然不同的训练特性：

1.  *LSTM (欠拟合/瓶颈)*:
  - 验证集 Loss 始终较高 (停留在 1.05 左右)。
  - 模型难以捕捉文本深层的语义特征，性能在 58% 左右触达天花板。

2. *TinyLLM (过拟合)*:
  - *"昙花一现"*：模型在 Epoch 1 就达到了最佳性能 (Loss 0.81)。
  - 随后验证集 Loss 迅速飙升至 1.00 以上，这表明模型参数量对于该数据集可能过大，或者在预训练知识不足的情况下，模型倾向于死记硬背训练数据中的噪声。

3.  *RoBERTa-Large (稳健收敛)*:
  - 验证集 Loss 持续下降并稳定在 0.73 左右。
  - 得益于大规模预训练，模型具备极强的泛化能力，未出现明显的过拟合迹象。


---

=== 极端情感捕捉能力分析 (Recall Analysis)

本任务最大的难点在于 *类别不平衡* (Neutral 占 50%)。我们重点关注模型对 *Very Negative (0)* 和 *Very Positive (4)* 的识别能力。

#figure(
  tablem[
    | 真实标签 | LSTM Recall | TinyLLM Recall | RoBERTa Recall |
    | :--- | :--- | :--- | :--- | 
    | 0 (极负) | 13% | 23% | 47% |
    | 1 (负面) | 40% | 52% | 61% |
    | 2 (中性) | 81% | 80% | 79% |
    | 3 (正面) | 40% | 57% | 62% |
    | 4 (极正) | 21% | 30% | 57% | 
  ],
  caption: "各类别召回率 (Recall) 详细对比"
)

*数据洞察：*
- *LSTM* 几乎是“瞎猜”情感，它倾向于把所有极端样本都预测为中性。
- *TinyLLM* 对于弱情感的区分能力有显著提升，但仍漏掉了 70% 以上的极端样本。
- *RoBERTa* 对于极端样本的识别能力进一步增强，召回率接近 50%。

---

=== 混淆矩阵形态分析

对比三个模型的混淆矩阵，可以清晰地看到预测分布的变化趋势：

1.  *中心坍缩 (LSTM)*: 预测结果高度集中在 Label 2 (Neutral) 列，呈现垂直长条状。模型采取了“由于不确定，所以猜中性”的保守策略。
2.  *对角线强化 (RoBERTa)*: 混淆矩阵的对角线明显变亮，特别是在 Label 0 和 Label 4 的角落。这代表模型真正理解了语义，而非利用数据分布漏洞。
3.  *邻类漂移 (Common Issue)*: 所有模型的主要错误都集中在 *相邻类别* (如把 0 预测成 1，把 4 预测成 3)。几乎没有模型会将 0 预测成 4。这说明模型都成功学到了情感的 *连续性特征*。

---

== 总结

通过之前的实验以及模型表现，我们得出以下结论：

1.  *架构决定上限*：LSTM 受限于结构，无法有效处理长文本和复杂语义；Transformer 架构（TinyLLM/RoBERTa）显著优于 RNN。
2. *预训练是关键*：在小样本（极端类别样本少）场景下，RoBERTa 携带的先验知识是解决 *Cold Start* 和 *不平衡问题* 的关键。预训练时间不够的 TinyLLM 容易陷入过拟合。
3. *Accuracy 的欺骗性*：LSTM 的 58% Accuracy 背后是接近 0 的极端情感召回率；TinyLLM/RoBERTa 的约 70% Accuracy 代表了更均衡、更可用的模型。
